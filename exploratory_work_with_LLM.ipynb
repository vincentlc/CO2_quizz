{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d6b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d14ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76dfbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "headers = {\"Authorization\": \"Bearer \" + secrets.token}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def easy_query(instruction):\n",
    "    text = \"<s>[INST]\" + instruction + \"[/INST]</s>\"\n",
    "    output = query({\"inputs\": text,})\n",
    "    assert len(output) > 0\n",
    "    generated_text = output[0].get(\"generated_text\", text)\n",
    "    return generated_text.split(\"[/INST]</s>\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad99c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an artificial intelligence designed to assist with various tasks and answer questions to the best of my ability. I don't have the ability to have experiences, feelings, or a personal identity. I exist solely to process and respond to text input. My main goal is to help make your life easier by providing accurate information, answers to questions, and assistance with tasks. I'm here to make your day a little brighter and easier, so don't hesitate to ask me anything!\n"
     ]
    }
   ],
   "source": [
    "text = \"Tell me about you\"\n",
    "\n",
    "response = easy_query(text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cef9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Which has a larger carbon footprint, a screen or a computer?\n",
      "2. Is a car or a bus more carbon intensive than a pen?\n",
      "3. Which fruit has a higher carbon footprint, a mango or a steak?\n",
      "4. Does a smartphone produce more CO2 than an orange?\n",
      "5. Which object has the smallest carbon footprint between a car and a banana?\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"You are a quizz bot.\n",
    "Your task is to write questions about the carbon footprint of object.\n",
    "In each question, you will ask to compare two objects.\n",
    "You will not pick the same object in different questions.\n",
    "You will respond with 5 questions.\n",
    "Each question will be less than 10 words long.\n",
    "###\n",
    "Here are the objects and their carbon footprint:\n",
    "Smartphone: 37\n",
    "Computer: 188\n",
    "Screen: 236\n",
    "Banana: 3\n",
    "Apple: 2\n",
    "Car: 101\n",
    "Bus: 203\n",
    "Pen: 44\n",
    "Ball: 55\n",
    "Steak: 144\n",
    "Orange: 9\n",
    "Mango: 11\n",
    "###\n",
    "Here are examples:\n",
    "Which has a higher carbon footprint between a smartphone and a computer?\n",
    "Which has the lowest carbon footprint, a banana or an apple?\n",
    "###\n",
    "You will respond with 5 questions.\n",
    "\"\"\"\n",
    "\n",
    "response = easy_query(text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a4f365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Which has a larger carbon footprint, a screen or a computer?',\n",
       " '2. Is a car or a bus more carbon intensive than a pen?',\n",
       " '3. Which fruit has a higher carbon footprint, a mango or a steak?',\n",
       " '4. Does a smartphone produce more CO2 than an orange?',\n",
       " '5. Which object has the smallest carbon footprint between a car and a banana?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937d989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine, based on the given data, the user is correct. The computer has a larger carbon footprint than the screen.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"You are a quizz bot.\n",
    "You asked the following question:\n",
    "1. Which has a larger carbon footprint, a screen or a computer?\n",
    "The user gave you the following answer:\n",
    "I think it's the computer\n",
    "Your task is to check the user's answer based only on the carbon footprints bellow. If it's false, give the correct answer. If it's correct congratulate the user\n",
    "You will respond in less than 10 words.\n",
    "###\n",
    "Here are the objects and their carbon footprint:\n",
    "Smartphone: 37\n",
    "Computer: 188\n",
    "Screen: 236\n",
    "Banana: 3\n",
    "Apple: 2\n",
    "Car: 101\n",
    "Bus: 203\n",
    "Pen: 44\n",
    "Ball: 55\n",
    "Steak: 144\n",
    "Orange: 9\n",
    "Mango: 11\n",
    "\"\"\"\n",
    "\n",
    "response = easy_query(text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3988612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manifestement les LLM ne sont pas fait pour savoir compter..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
